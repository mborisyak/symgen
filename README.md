# SymGen

SymGen is an interpreter and generator of symbolic expressions. It uses mixed stack-memory machines for evaluation
and stochastic context-free grammars for generating symbolic expressions.

## Why?

For sampling large datasets of "low-complexity" regression and classification tasks,
generated by symbolic expressions of limited size.

## Evaluation

### Assembly language

SymGen uses [reverse Polish notation](https://en.wikipedia.org/wiki/Reverse_Polish_notation) for expressions.
Instruction set of the machine comes from a library of operators, which can be easily extended with custom ones.
```python
import symgen
machine = symgen.StackMachine(symgen.lib.core, symgen.lib.std)
```
All operators, except for the core ones, have unique name (typically 3-4 letters), like `add`, `mul`.
Besides the names, *the core operators* have special syntax:
- `<float | integer>`, e.g., `1.0` --- the `const` operator, pushes the constant into the stack;
- `(<integer>)`, e.g., `(0)` --- the `variable` operator, pushes the expression's input variable into the stack
  (indexing starts with zero);
- `[<integer>]`, e.g., `[1]` --- the `load` operator, pushes the content of the memory cell into the stack;
- `{<integer>}`, e.g., `{3}` --- the `store` operator, stores the top value from the stack into the memory cell,
the value is removed from the stack.

Below are some examples of expressions:
```
### adds 1 and 2
1.0 2.0 add
### incriments the first input variable
(0) 1 add
1 (0) add
### x / (x + y)
(0) (0) (1) add div
### sqrt(x ** 2 + y ** 2)
(0) (0) mul (1) (1) mul add sqrt
### p(x) log p(x) where p(x) = 1 / sqrt(2 pi) exp(-x * x / 2) (the constant is precomputed)
0.3989422804014327 2 (0) (0) mul div neg exp mul {0} [0] [0] log mul
```

Assembly langauge can be evaluated via `machine.evaluate(expression, *inputs)` or
`machine.__call__(expression, inputs=None, *, out=None)`.
The latter method expected inputs as a numpy array with the shape `(number of the input variables, *batch dimensions)`
and can write to a buffer `out` with the similar dimensions.

```python
machine.evaluate('1.0 2.0 add') # 3.0
machine.evaluate('(0) (0) mul (1) (1) mul add sqrt', 3.0, 4.0) # 5.0
machine('(0) (0) mul (1) (1) mul add sqrt', np.array([3.0, 4.0])) # np.array([5.0])
```

*Note:* arguments for functions of two and more variables are taken starting from the top of the stack, which results 
in the argument order being reversed compared to the conventional notation.
For example, `(0) (1) div` is equivalent to `(1) / (0)`.
In general, `f(arg_1, arg_2, ..., arg_n)` is equivalent to `arg_n, ..., arg_2, arg_1 f` in reverse Polish notation.

### Expression code

Expressions are stored as lists of operations, where each operation is a tuple with the name of the operator and
the optional argument, for example: `[('const', 1.0), ('const', 1.0), ('add', )]`.
`symgen.StackMachine` accepts both: an expression as a string and as a list of operations. 

An expression in the assembly language can be parsed via `symgen.StackMachine.parse`:
```python
machine = symgen.StackMachine(symgen.lib.core, symgen.lib.std)
print(machine.parse('1.0 2.0 add'))
# prints [('const', 1.0), ('const', 2.0), ('add',)]
```

### Why stack machines?

Stack machines are nicely suited for symbolic expressions. Most of the mathematical expressions can be
effortlessly converted into reverse Polish notation and executed on a stack machine: `(x + y) * z -> x y + z *`.
Naturally, reverse Polish notation is easy and intuitive to work with when generating random expressions.

While it is also possible to convert an expression into the format of RAM / register machines, they come with an additional
hurdle of keeping track of memory / registers: one either has to compile reverse Polish notations into RAM / register machine code
or directly generate such code.

### Why mixed stack-memory machines?

Stack machines have a flaw: they can't easily reuse results of subexpressions.
For example, to compute `p(x) log p(x)` where `p(x)` is some probability density, one has to
duplicate all computations for `p(x)`. Memory operators (`store` and `memory`, `{n}` and `[n]`) allow to
introduce temporary variables into the expression: `<expression for p> {0} [0] [0] log mul`.
An alternative solution, the stack duplication operator, is cumbersome to deal with during expression generation.
Another possibility, copying subexpressions during generation, wastes computational time and needlessly complicates
the generation process.

### Expanding the instruction set

One can introduce a new set of instructions by simply providing a dictionary with the Python functions:
```
my_library = dict(
  inc=lambda x: x + 1,
  sqrt=lambda x: np.sqrt(x),
)
```

`symgen` analyses the signature of the function and treats all **non-keyword-only** arguments as operator inputs.
The operator can also receive the following additional arguments (if they are declared as keyword-only):
- `argument` --- the argument of the operator, for example, when executing an operator `('const', 1.0)`
`1.0` is passed as `argument`. Multiple values can be passed as a tuple, e.g., `('linear', (2.0, 1.0))`;
- `out` --- output buffer, by analogy with the most numpy functions;
- `inputs` --- inputs variables stored as a single numpy array with shape `(dim, *batch dimensions)`;
- `memory` --- a numpy buffer that holds current state of the memory.

Normally, only the first two arguments are needed for custom operators, the latter two are used by the core operators.

*Note:* to define a keyword-only arguments one can use the
[star-syntax](https://docs.python.org/3/reference/compound_stmts.html#function),
for example, `lambda positional, *, keyword_only:`

*Note:* it is preferable to use the `out` argument and directly write the results into the buffer to avoid needless
copying, for example (note `[:]` before `out`):
```
inc = lambda x, *, out: out[:] = x + 1
```
or
```
inc = lambda x, *, out: np.add(x, 1, out=out)
```

If an operator uses `out` argument its output is simply ignored.
Most numpy functions support directly writing the result into a buffer (also via an optional `out` argument).

## Generating random expressions

### Grammar

SymGen uses (enhanced) context-free grammar for generating random expressions.
A grammar extends instruction set (terminal symbols) with non-terminal symbols: each non-terminal symbol
is expanded according to the probabilistic transition table until no non-terminal symbols remains.
Transition are picked randomly and are independent of the surrounding expressions (i.e., context-free).
For example, the following grammar generates random expressions with `add` and `mul` operators:
```
expr ->
    expr expr add with probability = 0.2
    expr expr mul with probability = 0.2
    constant with probability = 0.6
constant ->
    0 with probability = 0.2
    1 with probability = 0.2
    2 with probability = 0.2
    3.1415 with probability = 0.2
    2.7182 with probability = 0.2
```

In SymGen this grammar can be defined as follows:
```python
import math, random
import symgen
from symgen.generator import GeneratorMachine, symbol, op

libraries = (symgen.lib.core, symgen.lib.std)

expr = symbol('expr')
constant = symbol('constant')

rules={
  expr: {
    expr + expr + op('add'): 0.2,
    expr + expr + op('mul'): 0.2,
    constant: 0.6,
  },
  constant: {
    op('const', 0.0): 0.2,
    op('const', 1.0): 0.2,
    op('const', 2.0): 0.2,
    op('const', math.pi): 0.2,
    op('const', math.e): 0.2,
  }
}

rng = random.Random(1234567)
generator = GeneratorMachine(libraries, rules=rules)

random_expression = generator(rng, expr)
```

`symbol(<symbol name>)(` creates a non-terminal symbol with the corresponding name.
`rules` is a dictionary that maps `Condition` into a transition table: a dictionary mapping `Expansion`s into probabilities
(probability values are automatically normalized to 1).

If the transition table contains only one expansion, one can use the simplified syntax:
```python
rules={
  expr: subexpr + subexpr + op('add')
}
```
Also `expr: None` is an alternative to `expr: {}`.

`op(<name>, [<argument>])` instructs the generator to create an operation.


### Runaway grammars

It is quite easy to produce a "runaway" grammar: grammar that has a significant chance of exceeding any reasonable limits.
For example, the following grammar:
```
expr -> expr expr add, p = 0.9;
expr -> constant, p = 0.1;
```
has a non-zero chance of "running away" during generation.

It is highly advisable to write a priori finite grammars. The following section introduces the extension of the free grammar
that helps us, among other things, to constrain the generation process.

### Context and conditions

During the expansion process, non-terminal symbols can carry a context represented by a dictionary.
To set the context, one can simply call the symbol and provide the context via keyword arguments:
```python
from symgen import Grammar, symbol

expr = symbol('expr')
invocation = expr(i=1, j=2)
```
By analogy with functions, a symbol with a context is called invocation.

The generator can be instructed to modify the context by supplying the update functions.
For example, the following generator:
```python
rules = {
  expr : expr(i=lambda i, j: i + j, j=lambda i: i)
}

generator = GeneratorMachine(lib, rules=rules)
generator(rng, expr(i=1, j=1))
```
computes the Fibonacci sequence (and also never finishes, see *conditional transitions* below).

The context variables are matched by name, thus, the context update functions must have arguments with
the same name as variables in the context.

If a variables does not have an update function, it is passed without modification.

Context is (supposed to be) *immutable*, each invocation creates a new modified context
and is unaffected by the surrounding expansions. In the following example:
```
rules = {
  expr : subexpr(i=lambda i: i + 1) + subexpr(i=lambda i: i + 2)
}
```
the update function in each `subexpr` is applied to the context of `expr` and doesn't influence another `subexpr`.
The exceptions to this rule include special context variables that are managed by the generator (see below). 

*Note:* `symgen` does not enforce or track immutability, it is possible to modify the original context if the value
is, e.g., a list:
```
def update(a_list):
  a_list.append(len(a_list))
  return a_list

rules = {
  expr : expr(a_list=update) + expr(a_list=update)
}
```
The expansion of the first term expands the original list, thus, the second term will receive a modified value.
It is advisable to be careful with mutable collections.

### Conditional operations

The context can be used to generate operations:
```python
rules = {
  expr: op('variable', 0) + op('const', lambda i: float(i)) + op('add')
}
```
produces an expression that increments the first input variable by what the context variable `i` holds.

### Conditional transitions

Additionally, context can be used in *conditional transitions*:
```python
N = ...

rules = {
  expr.when(lambda depth: depth < N): {
    expr(depth=lambda depth: depth + 1) + expr(depth=lambda depth: depth + 1) + op('add'): 1.0,
    expr(depth=lambda depth: depth + 1) + expr(depth=lambda depth: depth + 1) + op('mul'): 1.0,
    expr(depth=lambda depth: depth + 1): 1.0
  },
  expr.when(lambda depth: depth >= N): op('variable', 0)
}
```
that switches transition tables on/off depending on the context.

The example above demonstrated a useful pattern of an a priori finite grammar.

*Note:* if multiple conditions are satisfied, the active tables are **merged**. Transition likelihoods are
automatically normalized. The transition produced by a simplified syntax `expr: expansion`
is assigned the likelihood of `1.0`.

### Conditional likelihoods

Likelihoods cna be made conditional by replacing concrete values with functions that accept context variables and
output a concrete value:
```python
expr: {
  expr(depth=lambda depth: depth + 1) + expr(depth=lambda depth: depth + 1) + op('add'): lambda depth: 1 / (depth + 1),
  op('variable', 0): 1.0
}
```
As likelihoods are converted into probabilities by normalizing their sum to 1, the probability of the first transition
decreases with the depth of expression ensuring that the expansion almost surely stops.

### Auto-updates

*Auto-updates* are automatically appended to every invocation, unless explicitly overridden.
`Symbol.auto` method provides a way to declare auto-updates.
It is especially useful for tracking variables like expression depth:

```python
expr = symbol('expr').auto(depth=lambda depth: depth + 1)

rules = {
  expr.when(lambda depth: depth < limit): expr + expr + op('add'),
  expr.when(lambda depth: depth >= limit): op('variable', 0),
}
```

### Local context

Update functions of are evaluated independently. In some cases, this might lead to wasteful computations if
the updates share heavy computations. Local context allows to introduce temporary variables into the update functions:
- local context is not propagated into the next symbol;
- it is computed before executing the usual update functions and the local variables are available for the context update functions;
- unlike normal updates, it is computed sequentially --- an update function (or rather definition) can use variables computed before it.

Local context can be declared via `where` method. Declaring local context of a `Symbol` simply passes it to its invocations.

```python
expr = symbol('expr').where(t1=lambda i: 2 * i + 1)
rules = {
  expr.when(lambda t1: t1 < 2 * N + 1): expr(i=lambda t1, t2: t1 + t2).where(t2=lambda t1, i: t1 - 3 * i),
  expr: op('const', lambda t1: t1 / 3.0),
}
```
In the example above, the local variable `t1` is available for computing `t2`, and both, `t1` and `t2`, are used
for computing the update of `i`.
Note that the local context declared at the symbol level is also available for conditions and operations.
The latter can also declare their own local variables.

Local context can be especially useful to avoid recomputing statistics on large arrays (see *tracing* below).

### Random generator

Random generator (Python's `random.Random`) is available via `rng` keyword in the same manner as context variables:
```python
rules = {
  expr: op('const', lambda rng: rng.normalvariate())
}
```

The random generator, however, is not a context variable and attempting to update it will result in an error.
Moreover, even within the same expansion, invocations receive generators with different internal states. 

### Tracing

A naive approach at generating expressions would quickly result in pathological cases:
NaNs, infinities or simply very small or very large numbers.
One could filter badly behaved expressions post factum, however,
the chances to produce a such an expression sharply raise with the increase in complexity.

Moreover, it's quite difficult to construct a set of rules that produce complex and, at the same time, stable
expressions.

`symgen.GeneratorMachine` can evaluate (trace) results of the expression as it is being generated.
To enable tracing, one should supply `inputs` argument to the `GeneratorMachine.__call__` method.
The `inputs` array should have the same shape as in `StackMachine.__call__`.
The partial results are available via the following keywords:
- `inputs` holds the original array;
- `stack` --- a list with the current state of the stack;
- `memory` --- a dictionary (`int -> np.ndarray`) with the current state of memory.

Note that, unlike context variables, `stack` and `memory` change from one invocation to another:
```python
rules = {
  expr: subexpr1 + subexpr2,
  ...
}
```
`subexpr2` would receive results of evaluating `subexpr1`.
Conditions and operations can also access the same variables.

*Important note:* auto-updates operate with the `stack` at the moment of expansion (as one would expect), however,
the local context defined at the symbol level is evaluated **before** the expansion. For example:

```python
expr = symbol('expr').
rules = {
  expr: subexpr1 + subexpr2,
  ...
}
```


### Rejection sampling

`symgen` allows using rejection sampling on the subexpression level via `check`


